{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"file_name\": \"image1.jpg\", \"ground_truth\": \"{\\\"gt_parse\\\": {\\\"surname\\\": \\\"Sharapova\\\", \\\"name\\\": \\\"Maria Yourievna\\\", \\\"sex\\\": \\\"F\\\", \\\"birthday\\\": \\\"04/19/1987\\\", \\\"birthplace\\\": \\\"Niagan\\\"}}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def create_sets(df, train=0.7, val=0.2, test=0.1):\n",
    "    \"\"\"\n",
    "    train, val and test are the proportions of the images\n",
    "    that go in each split.\n",
    "    \"\"\"\n",
    "    if train + val + test != 1:\n",
    "        raise ValueError(\"train + val + test != 1\")\n",
    "\n",
    "    # Create the folders\n",
    "    train_folder = \"data/train\"\n",
    "    val_folder = \"data/val\"\n",
    "    test_folder = \"data/test\"\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # Shuffle your data\n",
    "    samples = df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    # Compute the number of image for each split\n",
    "    n = len(samples)\n",
    "    n_train = train * n\n",
    "    n_val = val * n\n",
    "    n_test = test * n\n",
    "\n",
    "    for idx, row in tqdm(samples.iterrows(), total=samples.shape[0]):\n",
    "        data = {\n",
    "            \"surname\": row[\"surname\"]\n",
    "            \"name\": row[\"name\"]\n",
    "            \"sex\": row[\"sex\"]\n",
    "            \"birthday\": row[\"birthday\"]\n",
    "            \"birthplace\": row[\"birthplace\"]\n",
    "        }\n",
    "        file_name = row[\"filename\"]\n",
    "\n",
    "        gt_parse = {\"gt_parse\": data}\n",
    "        \n",
    "        line = {\n",
    "            \"file_name\": file_name,\n",
    "            \"ground_truth\": json.dumps(gt_parse)\n",
    "        }\n",
    "        \n",
    "        # We assume that your images are in\n",
    "        # a folder named \"images/\"; correct if necessary\n",
    "        image_path = os.path.join(\"images\", file_name)\n",
    "\n",
    "        # Copy the image in one of the folders\n",
    "        # and append a line to metadata.jsonl\n",
    "        if idx < n_train:\n",
    "            dest_path = os.path.join(\"data/train/\", file_name)\n",
    "            shutil.copyfile(image_path, dest_path)\n",
    "            with open(\"data/train/metadata.jsonl\", \"a\") as f:\n",
    "                f.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "        elif n_train <= idx < n_train + n_val:\n",
    "            dest_path = os.path.join(\"data/val/\", file_name)\n",
    "            shutil.copyfile(image_path, dest_path)\n",
    "            with open(\"data/val/metadata.jsonl\", \"a\") as f:\n",
    "                f.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "        elif n_train + n_val <= idx < n_train + n_val + n_test:\n",
    "            dest_path = os.path.join(\"data/test/\", file_name)\n",
    "            shutil.copyfile(image_path, dest_path)\n",
    "            with open(\"data/test/metadata.jsonl\", \"a\") as f:\n",
    "                f.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "create_sets(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
